# Week03
## 决定可以通过机器做出，但责任需要我们自己承担。
> 我们可以并且需要使用计算机 来帮助我们做更好的决策，但我们也需要在判断中加入道德义务，在这个框架下使用算法,而不是像人与人之间相互推卸那样，就把责任转移给机器。

* 如今，我们用计算机来做各种决策，包括人们面临的新决策。我们向计算机询问多解的、主观的、开放性的或意义深远的问题。我们在复杂的人类事务上的主观决策无法影响计算机。我们必须认识到，把数学和计算引入解决复杂的、高价值的人类事务中，并不能带来客观性，相反，人类事务的复杂性会扰乱算法。
* 机器为何要做选择，因为设计者制定了规则。也就是说机器的选择可能会包含设计者的想法，这会影响算法的准确判断。
*  逻辑是我们推理并得出道德选择的方式， **逻辑是编码机器道德的理想选择，为此我们需要培养算法的怀疑、复查和调研能力。我们需要确保有人为算法负责，为算法审查，并切实的公开透明。** 
### 机器学习
* 复杂算法的发展使得计算机可以识别人脸、破解笔迹、识别信用卡欺诈、屏蔽垃圾信息、翻译语言等等，这都来源与一种叫“机器学习”方法。机器学习不想传统程序一样，需要给计算机详细、准确的逐条指令。它更像是你给系统 喂了很多数据，包括非结构化数据，比如我们在数字生活中 产生的数据。系统扎进这些数据中学习，重要的是，这些系统不再局限单一答案。 **他们得出的不是一个简单的答案，而是概率性的：这个更像是你在寻找的.** 
* 它的缺点在于，我们无法清楚的了解系统学到了什么，事实上，这也正是它的强大之处。不像是给计算机下达指令，更像是在训练一个机器狗，我们无法精确的了解和控制它。
*  计算机系统能根据零散的数据，推断出关于你的一切，甚至你没有公开的事。把决策权给予我们并不完全了解的机器，可能会在我们不知情的状况下构建一种新的社会。
* 系统通常使用我们真实的行为数据来训练。它们可能只是在反馈我们的偏见，这些系统会继承我们的偏见，并把它们放大，然后反馈给我们。我们的机器智能系统,会在一些不符合人类出错模式的问题上出错。人类总是会有偏见，法庭上、新闻机构、战争中的，决策者等等，他们都会犯错，我们无法抛开这些困难的问题，我们不能把我们自身该承担的责任推给机器。

![机器学习](https://gitee.com/uploads/images/2019/0427/002024_ae397d27_2230768.jpeg "v2-c3c063000cd95e44dacf02dc50f4f10e_hd.jpg")
## 理解数据：批判性思维
> 数据自己不会创造意义， 是我们创造数据的意义.
*  我们不是只能被动地接受数据和科技。我们能改变科技在我们生活中扮演的角色，也能改变享受数据带来的恩惠的方式，但要实现这一目的，思考方式固然重要，我们也要对如何解读数据投以同样高的关注度。
*   **我们要做的是，积极进行批判性思维。** 
* 批判性思维:批判性思维指的是技能和思想态度，没有学科边界，任何涉及智力或想像的论题都可从批判性思维的视角来审查。批判性思维既是一种思维技能，也是一种人格或气质；既能体现思维水平，也凸显 **现代人文精神** 。
* 数据的意义是由人所创造，那么赋予数据怎么样的意义也是一个重要的问题。好钢用在刀刃上，力量用在行善上，就显得尤为重要。
### 参考来源
1. [批判性思维](https://baike.baidu.com/item/%E6%89%B9%E5%88%A4%E6%80%A7%E6%80%9D%E7%BB%B4)
2. [机器伦理学：机器人道德规范的困境](http://finance.huanqiu.com/roll/2015-08/7237005.html?agt=15435)
3. [机器学习：今天的草莓甜不甜？](https://zhuanlan.zhihu.com/p/32063544)
